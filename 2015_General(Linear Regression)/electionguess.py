import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import os
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import re
import warnings
warnings.filterwarnings('ignore')

class TurkishElectionPredictor:
    """
    TÃ¼rk seÃ§im verilerini kullanarak lineer regresyon ile parti oylarÄ±nÄ± tahmin eden kapsamlÄ± model
    """
    
    def __init__(self):
        self.models = {}
        self.pipelines = {}
        self.data = None
        self.parties = ['AK Parti', 'CHP', 'MHP', 'HDP']
        
    def load_and_prepare_data(self):
        """Veri yÃ¼kleme ve Ã¶n iÅŸleme"""
        print("ğŸ“Š Veri yÃ¼kleniyor ve hazÄ±rlanÄ±yor...")
        
        # Get the directory where this script is located
        script_dir = os.path.dirname(os.path.abspath(__file__))
        election_dir = os.path.join(script_dir, 'election')
        
        # TÃ¼m CSV dosyalarÄ±nÄ± yÃ¼kle
        files = os.listdir(election_dir)
        dataframes = []
        
        for file in files:
            if file.endswith('.csv'):
                file_path = os.path.join(election_dir, file)
                df = pd.read_csv(file_path)
                
                # Dosya adÄ±ndan dÃ¶nem bilgisini Ã§Ä±kar
                if 'haziran-2014' in file:
                    df['DÃ¶nem'] = '2014_Haziran'
                    df['DÃ¶nem_SayÄ±'] = 1
                elif 'haziran-2015' in file:
                    df['DÃ¶nem'] = '2015_Haziran'
                    df['DÃ¶nem_SayÄ±'] = 2
                elif 'kasÄ±m-2015' in file:
                    df['DÃ¶nem'] = '2015_KasÄ±m'
                    df['DÃ¶nem_SayÄ±'] = 3
                
                dataframes.append(df)
        
        # TÃ¼m veriyi birleÅŸtir
        self.data = pd.concat(dataframes, ignore_index=True)
        
        # Veri temizleme ve dÃ¶nÃ¼ÅŸtÃ¼rme
        self._clean_data()
        self._feature_engineering()
        
        print(f"âœ… Toplam {len(self.data)} anket verisi yÃ¼klendi")
        print(f"ğŸ“… DÃ¶nemler: {self.data['DÃ¶nem'].unique()}")
        print(f"ğŸ¢ Anket ÅŸirketleri: {self.data['Anketi Yapan'].nunique()} farklÄ± ÅŸirket")
        
    def _clean_data(self):
        """Veri temizleme iÅŸlemleri"""
        print("ğŸ§¹ Veri temizleniyor...")
        
        # Eksik deÄŸerleri 0 ile doldur (parti oylarÄ± iÃ§in)
        party_columns = ['AK Parti', 'CHP', 'MHP', 'HDP', 'BDP', 'SP', 'BBP', 'AP']
        for col in party_columns:
            if col in self.data.columns:
                self.data[col] = pd.to_numeric(self.data[col], errors='coerce').fillna(0)
        
        # HDP ve BDP birleÅŸtir (aynÄ± partinin farklÄ± dÃ¶nemlerdeki isimleri)
        if 'BDP' in self.data.columns:
            self.data['HDP'] = self.data['HDP'].fillna(0) + self.data['BDP'].fillna(0)
        
        # KatÄ±lÄ±mcÄ± sayÄ±sÄ±nÄ± numeric yap
        self.data['KatÄ±lÄ±mcÄ± sayÄ±sÄ±'] = pd.to_numeric(self.data['KatÄ±lÄ±mcÄ± sayÄ±sÄ±'], errors='coerce')
        
        # Anket ÅŸirketlerini kategorize et
        self.data['Anketi Yapan'] = self.data['Anketi Yapan'].fillna('Bilinmeyen')
        
        # Genel seÃ§im sonuÃ§larÄ±nÄ± iÅŸaretle
        self.data['GerÃ§ek_SeÃ§im'] = self.data['Anketi Yapan'].str.contains('Genel seÃ§imler', na=False)
        
    def _feature_engineering(self):
        """Ã–zellik mÃ¼hendisliÄŸi"""
        print("âš™ï¸ Ã–zellik mÃ¼hendisliÄŸi yapÄ±lÄ±yor...")
        
        # Anket ÅŸirketi gÃ¼venilirlik skoru (Ã¶rnek deÄŸerler)
        company_reliability = {
            'KONDA': 0.9, 'ORC': 0.85, 'Metropoll': 0.8, 'A&G': 0.8,
            'GENAR': 0.75, 'Gezici': 0.75, 'MAK': 0.7, 'SONAR': 0.7,
            'Andy-AR': 0.65, 'ANAR': 0.65, 'KamuAR': 0.6
        }
        self.data['Åirket_GÃ¼venilirlik'] = self.data['Anketi Yapan'].map(company_reliability).fillna(0.5)
        
        # KatÄ±lÄ±mcÄ± sayÄ±sÄ± kategorileri
        self.data['KatÄ±lÄ±mcÄ±_Kategori'] = pd.cut(
            self.data['KatÄ±lÄ±mcÄ± sayÄ±sÄ±'].fillna(1000), 
            bins=[0, 1000, 3000, 5000, float('inf')], 
            labels=['KÃ¼Ã§Ã¼k', 'Orta', 'BÃ¼yÃ¼k', 'Ã‡ok_BÃ¼yÃ¼k']
        )
        
        # Tarih Ã¶zelliÄŸi oluÅŸtur (basitleÅŸtirilmiÅŸ)
        self.data['Tarih_SÄ±rasÄ±'] = range(len(self.data))
        
        # Parti toplamlarÄ± ve oranlarÄ±
        self.data['Toplam_Oy'] = self.data[self.parties].sum(axis=1)
        
        for party in self.parties:
            self.data[f'{party}_Oran'] = self.data[party] / self.data['Toplam_Oy'] * 100
            
    def create_model_pipeline(self, target_party):
        """Belirli bir parti iÃ§in model pipeline'Ä± oluÅŸtur"""
        
        # Ã–zellikler
        numeric_features = ['KatÄ±lÄ±mcÄ± sayÄ±sÄ±', 'Åirket_GÃ¼venilirlik', 'DÃ¶nem_SayÄ±', 'Tarih_SÄ±rasÄ±']
        categorical_features = ['Anketi Yapan', 'DÃ¶nem', 'KatÄ±lÄ±mcÄ±_Kategori']
        
        # DiÄŸer parti oylarÄ±nÄ± Ã¶zellik olarak ekle
        other_parties = [p for p in self.parties if p != target_party]
        numeric_features.extend(other_parties)
        
        # Preprocessing pipeline
        numeric_transformer = StandardScaler()
        categorical_transformer = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')
        
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numeric_transformer, numeric_features),
                ('cat', categorical_transformer, categorical_features)
            ]
        )
        
        # Model pipeline
        pipeline = Pipeline([
            ('preprocessor', preprocessor),
            ('regressor', LinearRegression())
        ])
        
        return pipeline
        
    def train_models(self):
        """TÃ¼m partiler iÃ§in modelleri eÄŸit"""
        print("ğŸ¯ Modeller eÄŸitiliyor...")
        
        # Sadece anket verilerini kullan (gerÃ§ek seÃ§im sonuÃ§larÄ±nÄ± hedef olarak ayÄ±r)
        train_data = self.data[~self.data['GerÃ§ek_SeÃ§im']].copy()
        
        results = {}
        
        for party in self.parties:
            print(f"  ğŸ“ˆ {party} iÃ§in model eÄŸitiliyor...")
            
            # Veri hazÄ±rlama
            X = train_data.drop(columns=[party] + ['YapÄ±lÄ±ÅŸ Tarihi', 'GerÃ§ek_SeÃ§im'] + 
                               [col for col in train_data.columns if col.endswith('_Oran')])
            y = train_data[party]
            
            # NaN deÄŸerleri temizle
            mask = ~(X.isnull().any(axis=1) | y.isnull())
            X = X[mask]
            y = y[mask]
            
            if len(X) < 10:  # Minimum veri kontrolÃ¼
                print(f"    âš ï¸ {party} iÃ§in yeterli veri yok")
                continue
                
            # Train-test split
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
            
            # Model eÄŸitimi
            pipeline = self.create_model_pipeline(party)
            pipeline.fit(X_train, y_train)
            
            # Tahmin ve deÄŸerlendirme
            y_pred = pipeline.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            # SonuÃ§larÄ± kaydet
            self.pipelines[party] = pipeline
            results[party] = {
                'MSE': mse,
                'RMSE': np.sqrt(mse),
                'R2': r2,
                'Test_Size': len(X_test)
            }
            
            print(f"    âœ… {party}: RÂ² = {r2:.3f}, RMSE = {np.sqrt(mse):.2f}")
        
        # Modelleri kaydet
        self.save_models()
            
        return results
    
    def save_models(self):
        """
        EÄŸitilmiÅŸ modelleri kaydet
        """
        import pickle
        from datetime import datetime
        
        if self.pipelines:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            model_dir = os.path.join(script_dir, 'outputs', 'models')
            os.makedirs(model_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            model_filename = f'linear_regression_models_{timestamp}.pkl'
            model_path = os.path.join(model_dir, model_filename)
            
            # TÃ¼m modelleri ve meta bilgileri kaydet
            model_data = {
                'pipelines': self.pipelines,
                'parties': self.parties,
                'timestamp': timestamp,
                'model_type': 'Linear Regression'
            }
            
            with open(model_path, 'wb') as f:
                pickle.dump(model_data, f)
            
            print(f"ğŸ¤– Modeller kaydedildi: {model_path}")
        
    def predict_election_results(self, dÃ¶nem='2015_KasÄ±m'):
        """Belirli bir dÃ¶nem iÃ§in seÃ§im tahminleri yap"""
        print(f"ğŸ”® {dÃ¶nem} dÃ¶nemi iÃ§in tahminler yapÄ±lÄ±yor...")
        
        # Son anket verilerini al
        recent_data = self.data[
            (self.data['DÃ¶nem'] == dÃ¶nem) & 
            (~self.data['GerÃ§ek_SeÃ§im'])
        ].copy()
        
        if len(recent_data) == 0:
            print(f"âš ï¸ {dÃ¶nem} iÃ§in anket verisi bulunamadÄ±")
            return None
            
        predictions = {}
        
        for party in self.parties:
            if party not in self.pipelines:
                continue
                
            # Son 5 anketin ortalamasÄ±nÄ± al
            recent_party_data = recent_data.tail(5).copy()
            
            # Tahmin iÃ§in veri hazÄ±rlama
            X_pred = recent_party_data.drop(columns=[party] + ['YapÄ±lÄ±ÅŸ Tarihi', 'GerÃ§ek_SeÃ§im'] + 
                                           [col for col in recent_party_data.columns if col.endswith('_Oran')])
            
            # NaN deÄŸerleri temizle
            mask = ~X_pred.isnull().any(axis=1)
            X_pred = X_pred[mask]
            
            if len(X_pred) > 0:
                pred = self.pipelines[party].predict(X_pred)
                predictions[party] = np.mean(pred)
                
        return predictions
        
    def evaluate_predictions(self, dÃ¶nem='2015_KasÄ±m'):
        """Tahminleri gerÃ§ek sonuÃ§larla karÅŸÄ±laÅŸtÄ±r"""
        print(f"ğŸ“Š {dÃ¶nem} tahminleri deÄŸerlendiriliyor...")
        
        # Tahminleri al
        predictions = self.predict_election_results(dÃ¶nem)
        
        # GerÃ§ek sonuÃ§larÄ± al
        actual_results = self.data[
            (self.data['DÃ¶nem'] == dÃ¶nem) & 
            (self.data['GerÃ§ek_SeÃ§im'])
        ]
        
        if len(actual_results) == 0:
            print(f"âš ï¸ {dÃ¶nem} iÃ§in gerÃ§ek seÃ§im sonucu bulunamadÄ±")
            return None
            
        actual = actual_results.iloc[0]
        
        comparison = pd.DataFrame({
            'Parti': self.parties,
            'Tahmin': [predictions.get(party, 0) for party in self.parties],
            'GerÃ§ek': [actual[party] for party in self.parties]
        })
        
        comparison['Fark'] = comparison['GerÃ§ek'] - comparison['Tahmin']
        comparison['Mutlak_Fark'] = abs(comparison['Fark'])
        
        print("\nğŸ“‹ Tahmin vs GerÃ§ek SonuÃ§lar:")
        print(comparison.round(2))
        
        mae = comparison['Mutlak_Fark'].mean()
        print(f"\nğŸ“ˆ Ortalama Mutlak Hata (MAE): {mae:.2f} puan")
        
        return comparison
        
    def plot_trends(self):
        """Parti oylarÄ±nÄ±n zaman iÃ§indeki deÄŸiÅŸimini gÃ¶rselleÅŸtir"""
        print("ğŸ“ˆ Grafik Ã§iziliyor...")
        
        try:
            # Grafik ayarlarÄ±
            plt.style.use('default')  # Use default style instead of seaborn
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('TÃ¼rk SeÃ§im Anketleri - Parti OylarÄ± Trend Analizi', fontsize=16, fontweight='bold')
            
            colors = ['#FF6B35', '#004E89', '#A91D3A', '#7B2D26']
            
            for i, party in enumerate(self.parties):
                ax = axes[i//2, i%2]
                
                # DÃ¶nem bazÄ±nda grupla
                for j, dÃ¶nem in enumerate(self.data['DÃ¶nem'].unique()):
                    dÃ¶nem_data = self.data[self.data['DÃ¶nem'] == dÃ¶nem]
                    if not dÃ¶nem_data.empty:
                        ax.scatter(dÃ¶nem_data['Tarih_SÄ±rasÄ±'], dÃ¶nem_data[party], 
                                 label=dÃ¶nem, alpha=0.6, s=30)
                        
                # Trend Ã§izgisi
                trend_data = self.data.dropna(subset=[party])
                if len(trend_data) > 1:
                    z = np.polyfit(trend_data['Tarih_SÄ±rasÄ±'], trend_data[party], 1)
                    p = np.poly1d(z)
                    ax.plot(trend_data['Tarih_SÄ±rasÄ±'], p(trend_data['Tarih_SÄ±rasÄ±']), 
                           color=colors[i], linestyle='--', linewidth=2, alpha=0.8)
                
                ax.set_title(f'{party} Oy OranlarÄ±', fontweight='bold')
                ax.set_xlabel('Zaman')
                ax.set_ylabel('Oy OranÄ± (%)')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
            plt.tight_layout()
            
            # Ã‡Ä±ktÄ± klasÃ¶rÃ¼nÃ¼ oluÅŸtur
            script_dir = os.path.dirname(os.path.abspath(__file__))
            output_dir = os.path.join(script_dir, 'outputs', 'graphs')
            os.makedirs(output_dir, exist_ok=True)
            
            # Tarih damgasÄ± ekle
            from datetime import datetime
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            graph_filename = f'election_trends_{timestamp}.png'
            plot_path = os.path.join(output_dir, graph_filename)
            
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            print(f"ğŸ“ˆ Grafik kaydedildi: {plot_path}")
            
        except Exception as e:
            print(f"âš ï¸ Grafik Ã§izme hatasÄ±: {e}")
            print("ğŸ“Š Grafik olmadan analiz devam ediyor...")
        
    def run_analysis(self):
        """Tam analizi Ã§alÄ±ÅŸtÄ±r"""
        print("ğŸš€ TÃ¼rk SeÃ§im Tahmini Analizi BaÅŸlÄ±yor...\n")
        
        # 1. Veri yÃ¼kleme
        self.load_and_prepare_data()
        print("\n" + "="*50)
        
        # 2. Model eÄŸitimi
        results = self.train_models()
        print("\n" + "="*50)
        
        # 3. Model performanslarÄ±
        print("ğŸ“Š Model PerformanslarÄ±:")
        for party, metrics in results.items():
            print(f"  {party}: RÂ² = {metrics['R2']:.3f}, RMSE = {metrics['RMSE']:.2f}")
        print("\n" + "="*50)
        
        # 4. 2015 KasÄ±m tahminleri
        predictions_kasim = self.predict_election_results('2015_KasÄ±m')
        if predictions_kasim:
            print("ğŸ”® 2015 KasÄ±m SeÃ§imi Tahminleri:")
            for party, pred in predictions_kasim.items():
                print(f"  {party}: %{pred:.1f}")
        print("\n" + "="*50)
        
        # 5. Tahmin deÄŸerlendirmesi
        comparison = self.evaluate_predictions('2015_KasÄ±m')
        print("\n" + "="*50)
        
        # 6. Grafikler
        self.plot_trends()
        
        # 7. Rapor kaydet
        self.save_analysis_report(results, predictions_kasim, comparison)
        
        print("\nâœ… Analiz tamamlandÄ±!")
        print("ğŸ“Š Grafikler: outputs/graphs/ klasÃ¶rÃ¼nde")
        print("ğŸ“„ Raporlar: outputs/reports/ klasÃ¶rÃ¼nde")
        print("ğŸ¤– Modeller: outputs/models/ klasÃ¶rÃ¼nde")
    
    def save_analysis_report(self, results, predictions, comparison):
        """
        Analiz raporunu dosyaya kaydet
        """
        from datetime import datetime
        
        script_dir = os.path.dirname(os.path.abspath(__file__))
        report_dir = os.path.join(script_dir, 'outputs', 'reports')
        os.makedirs(report_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_filename = f'linear_regression_analysis_report_{timestamp}.txt'
        report_path = os.path.join(report_dir, report_filename)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*60 + "\n")
            f.write("         TÃœRKÄ°YE 2015 SEÃ‡Ä°M TAHMÄ°N RAPORU\n")
            f.write("              Linear Regression Analizi\n")
            f.write(f"                {datetime.now().strftime('%d.%m.%Y %H:%M')}\n")
            f.write("="*60 + "\n\n")
            
            # Model performanslarÄ±
            f.write("MODEL PERFORMANSLARI:\n")
            f.write("-" * 30 + "\n")
            for party, metrics in results.items():
                f.write(f"{party:15s}: RÂ² = {metrics['R2']:6.3f}, RMSE = {metrics['RMSE']:5.2f}\n")
            
            f.write("\n2015 KASIM SEÃ‡Ä°M TAHMÄ°NLERÄ°:\n")
            f.write("-" * 30 + "\n")
            if predictions:
                for party, pred in predictions.items():
                    f.write(f"{party:15s}: %{pred:5.1f}\n")
            
            f.write("\nTAHMÄ°N vs GERÃ‡EK KARÅILAÅTIRMA:\n")
            f.write("-" * 40 + "\n")
            if comparison is not None:
                for _, row in comparison.iterrows():
                    f.write(f"{row['Parti']:15s}: Tahmin=%{row['Tahmin']:5.1f}, GerÃ§ek=%{row['GerÃ§ek']:5.1f}, Fark={row['Fark']:+5.1f}\n")
                f.write(f"\nOrtalama Mutlak Hata: {comparison['Mutlak_Fark'].mean():.2f} puan\n")
            
            f.write(f"\nRapor oluÅŸturma zamanÄ±: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
        
        print(f"ğŸ“„ Analiz raporu kaydedildi: {report_path}")

# Ana program
if __name__ == "__main__":
    predictor = TurkishElectionPredictor()
    predictor.run_analysis()