import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib
matplotlib.use('Agg')  # GUI olmayan backend kullan
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

class TurkeyElectionPredictor:
    """
    TÃ¼rkiye SeÃ§im Tahmini iÃ§in GeliÅŸmiÅŸ Random Forest Modeli
    """
    def __init__(self):
        self.model = None
        self.preprocessor = None
        self.party_columns = ['AKP', 'CHP', 'Ä°YÄ°', 'HDP', 'MHP', 'SP']
        self.is_trained = False
        
    def load_and_clean_data(self, file_path):
        """
        Veriyi yÃ¼kler ve temizler
        """
        try:
            # CSV dosyasÄ±nÄ± oku
            df = pd.read_csv(file_path, encoding='utf-8')
            
            # BoÅŸ satÄ±rlarÄ± temizle
            df = df.dropna(how='all')
            
            print("Ham veri:")
            print(df.head())
            print(f"SÃ¼tunlar: {df.columns.tolist()}")
            
            # SayÄ±sal sÃ¼tunlarÄ± temizle ve dÃ¶nÃ¼ÅŸtÃ¼r
            for col in self.party_columns:
                if col in df.columns:
                    print(f"\n{col} sÃ¼tunu iÅŸleniyor...")
                    
                    # VirgÃ¼lleri nokta ile deÄŸiÅŸtir ve tÄ±rnak iÅŸaretlerini temizle
                    df[col] = df[col].astype(str).str.replace('"', '').str.replace(',', '.')
                    
                    # Range deÄŸerleri (50-52 gibi) ortalama al
                    df[col] = df[col].apply(self._process_range_values)
                    
                    # SayÄ±sal olmayan deÄŸerleri NaN yap
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    
                    # BoÅŸ deÄŸerleri doldurmak iÃ§in komÅŸu deÄŸerlerin ortalamasÄ±nÄ± al
                    df[col] = df[col].fillna(df[col].mean())
                    
                    print(f"{col} - NaN sayÄ±sÄ±: {df[col].isna().sum()}")
                    print(f"{col} - Ã¶rnek deÄŸerler: {df[col].dropna().head().tolist()}")
            
            # KatÄ±lÄ±mcÄ± sayÄ±sÄ±nÄ± temizle
            if 'KatÄ±lÄ±mcÄ± sayÄ±sÄ±' in df.columns:
                df['KatÄ±lÄ±mcÄ± sayÄ±sÄ±'] = df['KatÄ±lÄ±mcÄ± sayÄ±sÄ±'].astype(str).str.replace('.', '').str.replace(',', '').str.replace('"', '')
                df['KatÄ±lÄ±mcÄ± sayÄ±sÄ±'] = pd.to_numeric(df['KatÄ±lÄ±mcÄ± sayÄ±sÄ±'], errors='coerce')
                df['KatÄ±lÄ±mcÄ± sayÄ±sÄ±'] = df['KatÄ±lÄ±mcÄ± sayÄ±sÄ±'].fillna(2500)  # Ortalama deÄŸer
            
            # KararsÄ±z sÃ¼tununu temizle
            if 'KararsÄ±z' in df.columns:
                df['KararsÄ±z'] = df['KararsÄ±z'].astype(str).str.replace(',', '.').str.replace('"', '')
                df['KararsÄ±z'] = pd.to_numeric(df['KararsÄ±z'], errors='coerce')
                df['KararsÄ±z'] = df['KararsÄ±z'].fillna(8.0)  # Ortalama kararsÄ±z oranÄ±
            
            # Tarih sÃ¼tununu iÅŸle
            df['Tarih_Numeric'] = range(len(df))  # Kronolojik sÄ±ra
            
            # Eksik anket ÅŸirketi bilgilerini doldur
            if 'Anketi yapan' in df.columns:
                df['Anketi yapan'] = df['Anketi yapan'].fillna('Bilinmeyen')
            
            print(f"\nVeri yÃ¼klendi: {df.shape[0]} satÄ±r, {df.shape[1]} sÃ¼tun")
            
            # Her parti iÃ§in geÃ§erli veri sayÄ±sÄ±nÄ± gÃ¶ster
            for col in self.party_columns:
                if col in df.columns:
                    valid_count = df[col].notna().sum()
                    print(f"{col}: {valid_count} geÃ§erli veri")
            
            return df
            
        except Exception as e:
            print(f"Veri yÃ¼kleme hatasÄ±: {e}")
            return None
    
    def _process_range_values(self, value):
        """
        Range deÄŸerleri (50-52 gibi) ortalama deÄŸerle deÄŸiÅŸtirir
        """
        if isinstance(value, str) and '-' in value:
            try:
                parts = value.split('-')
                if len(parts) == 2:
                    return (float(parts[0]) + float(parts[1])) / 2
            except:
                pass
        return value
    
    def create_features(self, df):
        """
        GeliÅŸmiÅŸ Ã¶zellikler oluÅŸturur
        """
        features_df = df.copy()
        
        # Ana partiler iÃ§in oy toplamÄ±
        main_parties = ['AKP', 'CHP', 'Ä°YÄ°', 'HDP', 'MHP']
        if all(col in features_df.columns for col in main_parties):
            features_df['Total_Main_Parties'] = features_df[main_parties].sum(axis=1, skipna=True)
        
        # Ä°ttifak simÃ¼lasyonlarÄ±
        if all(col in features_df.columns for col in ['AKP', 'MHP']):
            features_df['Cumhur_Ä°ttifakÄ±'] = features_df['AKP'].fillna(0) + features_df['MHP'].fillna(0)
        
        if all(col in features_df.columns for col in ['CHP', 'Ä°YÄ°']):
            features_df['Millet_Ä°ttifakÄ±'] = features_df['CHP'].fillna(0) + features_df['Ä°YÄ°'].fillna(0)
        
        # Anket ÅŸirketi gÃ¼venilirlik skoru (basit)
        company_reliability = {
            'MetroPOLL': 0.9, 'SONAR': 0.85, 'Gezici': 0.8, 'ORC': 0.85,
            'Mediar': 0.75, 'Piar': 0.8, 'REMRES': 0.7
        }
        
        if 'Anketi yapan' in features_df.columns:
            features_df['GÃ¼venilirlik_Skoru'] = features_df['Anketi yapan'].map(company_reliability).fillna(0.6)
        
        # KatÄ±lÄ±mcÄ± sayÄ±sÄ±na gÃ¶re aÄŸÄ±rlÄ±k
        if 'KatÄ±lÄ±mcÄ± sayÄ±sÄ±' in features_df.columns:
            features_df['Sample_Weight'] = np.log1p(features_df['KatÄ±lÄ±mcÄ± sayÄ±sÄ±'].fillna(1000))
        
        # KararsÄ±z seÃ§men oranÄ±
        if 'KararsÄ±z' in features_df.columns:
            features_df['KararsÄ±z'] = pd.to_numeric(features_df['KararsÄ±z'], errors='coerce').fillna(0)
        
        return features_df
    
    def prepare_training_data(self, df):
        """
        EÄŸitim verisi hazÄ±rlar
        """
        # En az 3 partinin verisinin olduÄŸu satÄ±rlarÄ± al
        party_vote_counts = df[self.party_columns].notna().sum(axis=1)
        valid_rows = party_vote_counts >= 3
        clean_df = df[valid_rows].copy()
        
        if clean_df.empty:
            print("Yeterli temiz veri bulunamadÄ±!")
            return None, None
        
        print(f"KullanÄ±labilir satÄ±r sayÄ±sÄ±: {len(clean_df)}")
        
        # Eksik parti verilerini o partinin ortalama deÄŸeriyle doldur
        for col in self.party_columns:
            if col in clean_df.columns:
                mean_val = clean_df[col].mean()
                clean_df[col] = clean_df[col].fillna(mean_val)
        
        # Ã–zellikler
        feature_columns = []
        
        # SayÄ±sal Ã¶zellikler
        numeric_features = ['Tarih_Numeric', 'GÃ¼venilirlik_Skoru', 'Sample_Weight', 'KararsÄ±z']
        for col in numeric_features:
            if col in clean_df.columns:
                feature_columns.append(col)
        
        # Parti oy oranlarÄ± da Ã¶zellik olarak kullanÄ±labilir (Ã§apraz doÄŸrulama iÃ§in)
        for party in self.party_columns:
            if party in clean_df.columns:
                feature_columns.append(f"{party}_Vote_Share")
                clean_df[f"{party}_Vote_Share"] = clean_df[party]
        
        # Kategorik Ã¶zellikler
        categorical_features = ['Anketi yapan']
        for col in categorical_features:
            if col in clean_df.columns:
                feature_columns.append(col)
        
        X = clean_df[feature_columns]
        
        # Hedef deÄŸiÅŸken: En yÃ¼ksek oy alan parti
        party_votes = clean_df[self.party_columns]
        y = party_votes.idxmax(axis=1)
        
        # Regresyon iÃ§in de hazÄ±rlÄ±k yapabiliriz
        y_regression = clean_df[self.party_columns].values
        
        print(f"EÄŸitim verisi hazÄ±rlandÄ±: {X.shape[0]} Ã¶rnek, {X.shape[1]} Ã¶zellik")
        print(f"Hedef daÄŸÄ±lÄ±mÄ±:\n{y.value_counts()}")
        
        return X, y
    
    def train_model(self, X, y):
        """
        Random Forest modelini eÄŸitir
        """
        # Veri Ã¶n iÅŸleme pipeline'Ä±
        numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
        categorical_features = X.select_dtypes(include=['object']).columns.tolist()
        
        print(f"SayÄ±sal Ã¶zellikler: {numeric_features}")
        print(f"Kategorik Ã¶zellikler: {categorical_features}")
        
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numeric_features),
                ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)
            ]
        )
        
        # Random Forest modeli - parametreleri veri boyutuna gÃ¶re ayarla
        n_samples = len(X)
        if n_samples < 20:
            n_estimators = 50
            max_depth = 5
        else:
            n_estimators = 200
            max_depth = 10
        
        rf_model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_split=max(2, n_samples // 10),
            min_samples_leaf=1,
            random_state=42,
            class_weight='balanced'
        )
        
        # Pipeline oluÅŸtur
        self.model = Pipeline([
            ('preprocessor', preprocessor),
            ('classifier', rf_model)
        ])
        
        # KÃ¼Ã§Ã¼k veri seti iÃ§in farklÄ± yaklaÅŸÄ±m
        if n_samples < 10:
            # Ã‡ok kÃ¼Ã§Ã¼k veri setinde cross-validation kullan
            from sklearn.model_selection import cross_val_score
            self.model.fit(X, y)
            scores = cross_val_score(self.model, X, y, cv=min(3, n_samples))
            print(f"Cross-validation skorlarÄ±: {scores}")
            print(f"Ortalama doÄŸruluk: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})")
            
            # TÃ¼m veriyi test iÃ§in kullan
            y_pred = self.model.predict(X)
            train_score = self.model.score(X, y)
            
            print(f"EÄŸitim DoÄŸruluÄŸu: {train_score:.3f}")
            
        else:
            # Normal train-test split
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y if len(y.unique()) > 1 else None
            )
            
            self.model.fit(X_train, y_train)
            
            # Model performansÄ±nÄ± deÄŸerlendir
            train_score = self.model.score(X_train, y_train)
            test_score = self.model.score(X_test, y_test)
            
            print(f"EÄŸitim DoÄŸruluÄŸu: {train_score:.3f}")
            print(f"Test DoÄŸruluÄŸu: {test_score:.3f}")
            
            # Tahmin raporu
            y_pred = self.model.predict(X_test)
            print("\nSÄ±nÄ±flandÄ±rma Raporu:")
            print(classification_report(y_test, y_pred))
            
            X_test, y_test = X_test, y_test
        
        self.is_trained = True
        
        # Modeli kaydet
        self.save_model()
        
        return X, y, self.model.predict(X)
    
    def save_model(self):
        """
        EÄŸitilmiÅŸ modeli kaydet
        """
        import pickle
        import os
        from datetime import datetime
        
        if self.model is not None:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            model_dir = os.path.join(script_dir, 'outputs', 'models')
            os.makedirs(model_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            model_filename = f'random_forest_model_{timestamp}.pkl'
            model_path = os.path.join(model_dir, model_filename)
            
            # Model ve preprocessor'Ä± birlikte kaydet
            model_data = {
                'model': self.model,
                'preprocessor': self.preprocessor,
                'party_columns': self.party_columns,
                'timestamp': timestamp
            }
            
            with open(model_path, 'wb') as f:
                pickle.dump(model_data, f)
            
            print(f"ğŸ¤– Model kaydedildi: {model_path}")
    
    def predict_election_results(self, scenario_data):
        """
        SeÃ§im sonuÃ§larÄ±nÄ± tahmin eder
        """
        if not self.is_trained:
            print("Model henÃ¼z eÄŸitilmemiÅŸ!")
            return None
        
        # Tahmin yap
        prediction = self.model.predict(scenario_data)
        prediction_proba = self.model.predict_proba(scenario_data)
        
        # Senaryodaki gerÃ§ek oy oranlarÄ±nÄ± kullan (daha gerÃ§ekÃ§i sonuÃ§ iÃ§in)
        vote_shares = {}
        for party in self.party_columns:
            vote_col = f"{party}_Vote_Share"
            if vote_col in scenario_data.columns:
                vote_shares[party] = scenario_data[vote_col].iloc[0]
        
        # Model tahminini ve gerÃ§ek oy oranlarÄ±nÄ± birleÅŸtir
        if vote_shares:
            # Oy oranlarÄ±nÄ± normalize et
            total_votes = sum(vote_shares.values())
            if total_votes > 0:
                for party in vote_shares:
                    vote_shares[party] = (vote_shares[party] / total_votes) * 100
            return vote_shares, prediction
        
        # EÄŸer oy oranlarÄ± yoksa model tahminini kullan
        classes = self.model.classes_
        results = {}
        
        for i, party in enumerate(classes):
            avg_proba = prediction_proba[:, i].mean()
            results[party] = avg_proba * 100
        
        return results, prediction
    
    def create_prediction_scenarios(self):
        """
        FarklÄ± seÃ§im senaryolarÄ± oluÅŸturur
        """
        scenarios = []
        
        # Ortalama oy oranlarÄ±nÄ± hesapla (geÃ§miÅŸ verilerden)
        avg_votes = {
            'AKP_Vote_Share': 47.5,
            'CHP_Vote_Share': 24.0,
            'Ä°YÄ°_Vote_Share': 15.5,
            'HDP_Vote_Share': 11.0,
            'MHP_Vote_Share': 8.5,
            'SP_Vote_Share': 2.8
        }
        
        # Senaryo 1: YÃ¼ksek gÃ¼venilirlik, bÃ¼yÃ¼k Ã¶rneklem
        scenario1 = {
            'Tarih_Numeric': [25],
            'GÃ¼venilirlik_Skoru': [0.9],
            'Sample_Weight': [np.log1p(5000)],
            'KararsÄ±z': [5.0],
            'Anketi yapan': ['MetroPOLL'],
            **avg_votes
        }
        scenarios.append(("YÃ¼ksek GÃ¼venilirlik Senaryosu", scenario1))
        
        # Senaryo 2: AKP lehine deÄŸiÅŸim
        scenario2 = {
            'Tarih_Numeric': [25],
            'GÃ¼venilirlik_Skoru': [0.85],
            'Sample_Weight': [np.log1p(3000)],
            'KararsÄ±z': [6.0],
            'Anketi yapan': ['SONAR'],
            'AKP_Vote_Share': 50.0,
            'CHP_Vote_Share': 22.0,
            'Ä°YÄ°_Vote_Share': 14.0,
            'HDP_Vote_Share': 9.5,
            'MHP_Vote_Share': 7.0,
            'SP_Vote_Share': 2.5
        }
        scenarios.append(("AKP GÃ¼Ã§lÃ¼ Senaryo", scenario2))
        
        # Senaryo 3: Muhalefet gÃ¼Ã§lÃ¼
        scenario3 = {
            'Tarih_Numeric': [25],
            'GÃ¼venilirlik_Skoru': [0.8],
            'Sample_Weight': [np.log1p(2500)],
            'KararsÄ±z': [8.0],
            'Anketi yapan': ['Gezici'],
            'AKP_Vote_Share': 44.0,
            'CHP_Vote_Share': 27.0,
            'Ä°YÄ°_Vote_Share': 17.0,
            'HDP_Vote_Share': 12.0,
            'MHP_Vote_Share': 6.5,
            'SP_Vote_Share': 3.0
        }
        scenarios.append(("Muhalefet GÃ¼Ã§lÃ¼ Senaryo", scenario3))
        
        # Senaryo 4: YakÄ±n yarÄ±ÅŸ
        scenario4 = {
            'Tarih_Numeric': [25],
            'GÃ¼venilirlik_Skoru': [0.75],
            'Sample_Weight': [np.log1p(2000)],
            'KararsÄ±z': [10.0],
            'Anketi yapan': ['Piar'],
            'AKP_Vote_Share': 46.0,
            'CHP_Vote_Share': 25.5,
            'Ä°YÄ°_Vote_Share': 16.0,
            'HDP_Vote_Share': 11.0,
            'MHP_Vote_Share': 7.5,
            'SP_Vote_Share': 2.8
        }
        scenarios.append(("YakÄ±n YarÄ±ÅŸ Senaryosu", scenario4))
        
        return scenarios
    
    def visualize_results(self, results_dict):
        """
        SonuÃ§larÄ± gÃ¶rselleÅŸtirir
        """
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Bar chart
        parties = list(results_dict.keys())
        percentages = list(results_dict.values())
        
        colors = ['#FF6B35', '#1E90FF', '#32CD32', '#9932CC', '#FF1493', '#FFA500']
        bars = ax1.bar(parties, percentages, color=colors[:len(parties)])
        ax1.set_title('Tahmini SeÃ§im SonuÃ§larÄ±', fontsize=14, fontweight='bold')
        ax1.set_ylabel('Oy OranÄ± (%)')
        ax1.set_ylim(0, max(percentages) * 1.2)
        
        # Bar Ã¼zerine deÄŸerleri yaz
        for bar, pct in zip(bars, percentages):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                    f'{pct:.1f}%', ha='center', va='bottom', fontweight='bold')
        
        # Pasta grafiÄŸi
        ax2.pie(percentages, labels=parties, autopct='%1.1f%%', startangle=90, colors=colors[:len(parties)])
        ax2.set_title('Oy DaÄŸÄ±lÄ±mÄ±', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        
        # Ã‡Ä±ktÄ± klasÃ¶rÃ¼nÃ¼ oluÅŸtur
        import os
        script_dir = os.path.dirname(os.path.abspath(__file__))
        output_dir = os.path.join(script_dir, 'outputs', 'graphs')
        os.makedirs(output_dir, exist_ok=True)
        
        # Tarih damgasÄ± ekle
        from datetime import datetime
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        graph_filename = f'election_prediction_2018_{timestamp}.png'
        graph_path = os.path.join(output_dir, graph_filename)
        
        plt.savefig(graph_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š Grafik kaydedildi: {graph_path}")
    
    def generate_detailed_report(self, all_scenarios_results):
        """
        DetaylÄ± analiz raporu oluÅŸturur
        """
        print("\n" + "="*80)
        print("           TÃœRKÄ°YE 2018 SEÃ‡Ä°M TAHMÄ°N RAPORU")
        print("                Random Forest Analizi")
        print("="*80)
        
        # Ortalama sonuÃ§larÄ± hesapla
        all_parties = set()
        for _, results in all_scenarios_results:
            all_parties.update(results.keys())
        
        avg_results = {}
        for party in all_parties:
            scores = [results.get(party, 0) for _, results in all_scenarios_results]
            avg_results[party] = np.mean(scores)
        
        print("\nORTALAMA TAHMÄ°N SONUÃ‡LARI:")
        print("-" * 40)
        sorted_results = sorted(avg_results.items(), key=lambda x: x[1], reverse=True)
        
        for i, (party, score) in enumerate(sorted_results, 1):
            print(f"{i}. {party:15s}: %{score:5.1f}")
        
        print("\nSENARYO KARÅILAÅTIRMASI:")
        print("-" * 60)
        for scenario_name, results in all_scenarios_results:
            print(f"\n{scenario_name}:")
            sorted_scenario = sorted(results.items(), key=lambda x: x[1], reverse=True)
            for party, score in sorted_scenario:
                print(f"  {party:15s}: %{score:5.1f}")
        
        # Ä°statistiksel analiz
        print("\nÄ°STATÄ°STÄ°KSEL ANALÄ°Z:")
        print("-" * 40)
        winner = max(avg_results.items(), key=lambda x: x[1])
        print(f"En OlasÄ± Kazanan: {winner[0]} (%{winner[1]:.1f})")
        
        # Belirsizlik analizi
        party_variations = {}
        for party in all_parties:
            scores = [results.get(party, 0) for _, results in all_scenarios_results]
            party_variations[party] = np.std(scores)
        
        most_stable = min(party_variations.items(), key=lambda x: x[1])
        most_volatile = max(party_variations.items(), key=lambda x: x[1])
        
        print(f"En KararlÄ± Parti: {most_stable[0]} (Â±{most_stable[1]:.1f})")
        print(f"En DeÄŸiÅŸken Parti: {most_volatile[0]} (Â±{most_volatile[1]:.1f})")
        
        # Raporu dosyaya kaydet
        self.save_report(all_scenarios_results, avg_results, party_variations)
        
        return avg_results
    
    def save_report(self, all_scenarios_results, avg_results, party_variations):
        """
        DetaylÄ± raporu dosyaya kaydet
        """
        import os
        from datetime import datetime
        
        script_dir = os.path.dirname(os.path.abspath(__file__))
        report_dir = os.path.join(script_dir, 'outputs', 'reports')
        os.makedirs(report_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_filename = f'election_analysis_report_{timestamp}.txt'
        report_path = os.path.join(report_dir, report_filename)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("           TÃœRKÄ°YE 2018 SEÃ‡Ä°M TAHMÄ°N RAPORU\n")
            f.write("                Random Forest Analizi\n")
            f.write(f"                  {datetime.now().strftime('%d.%m.%Y %H:%M')}\n")
            f.write("="*80 + "\n\n")
            
            # Ortalama sonuÃ§lar
            f.write("ORTALAMA TAHMÄ°N SONUÃ‡LARI:\n")
            f.write("-" * 40 + "\n")
            sorted_results = sorted(avg_results.items(), key=lambda x: x[1], reverse=True)
            
            for i, (party, score) in enumerate(sorted_results, 1):
                f.write(f"{i}. {party:15s}: %{score:5.1f}\n")
            
            f.write("\nSENARYO KARÅILAÅTIRMASI:\n")
            f.write("-" * 60 + "\n")
            for scenario_name, results in all_scenarios_results:
                f.write(f"\n{scenario_name}:\n")
                sorted_scenario = sorted(results.items(), key=lambda x: x[1], reverse=True)
                for party, score in sorted_scenario:
                    f.write(f"  {party:15s}: %{score:5.1f}\n")
            
            # Ä°statistiksel analiz
            f.write("\nÄ°STATÄ°STÄ°KSEL ANALÄ°Z:\n")
            f.write("-" * 40 + "\n")
            winner = max(avg_results.items(), key=lambda x: x[1])
            f.write(f"En OlasÄ± Kazanan: {winner[0]} (%{winner[1]:.1f})\n")
            
            most_stable = min(party_variations.items(), key=lambda x: x[1])
            most_volatile = max(party_variations.items(), key=lambda x: x[1])
            
            f.write(f"En KararlÄ± Parti: {most_stable[0]} (Â±{most_stable[1]:.1f})\n")
            f.write(f"En DeÄŸiÅŸken Parti: {most_volatile[0]} (Â±{most_volatile[1]:.1f})\n")
            
            f.write(f"\nRapor oluÅŸturma zamanÄ±: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
        
        print(f"ğŸ“„ DetaylÄ± rapor kaydedildi: {report_path}")

def main():
    """
    Ana uygulama fonksiyonu
    """
    print("TÃ¼rkiye 2018 SeÃ§im Tahmini - Random Forest Analizi")
    print("=" * 55)
    
    # Predictor'Ä± baÅŸlat
    predictor = TurkeyElectionPredictor()
    
    # Script'in bulunduÄŸu dizini al ve CSV dosyasÄ±nÄ±n tam yolunu oluÅŸtur
    import os
    script_dir = os.path.dirname(os.path.abspath(__file__))
    csv_file_path = os.path.join(script_dir, "election", "all.csv")
    
    # Veriyi yÃ¼kle ve temizle
    df = predictor.load_and_clean_data(csv_file_path)
    if df is None:
        return
    
    # Ã–zellikler oluÅŸtur
    df_with_features = predictor.create_features(df)
    
    # EÄŸitim verisi hazÄ±rla
    X, y = predictor.prepare_training_data(df_with_features)
    if X is None:
        return
    
    # Modeli eÄŸit
    print("\nModel eÄŸitiliyor...")
    X_test, y_test, y_pred = predictor.train_model(X, y)
    
    # Senaryolar oluÅŸtur ve tahmin yap
    print("\nSeÃ§im senaryolarÄ± oluÅŸturuluyor...")
    scenarios = predictor.create_prediction_scenarios()
    all_results = []
    
    for scenario_name, scenario_data in scenarios:
        scenario_df = pd.DataFrame(scenario_data)
        results, predictions = predictor.predict_election_results(scenario_df)
        all_results.append((scenario_name, results))
        
        print(f"\n{scenario_name} SonuÃ§larÄ±:")
        for party, score in sorted(results.items(), key=lambda x: x[1], reverse=True):
            print(f"  {party}: %{score:.1f}")
    
    # DetaylÄ± rapor oluÅŸtur
    avg_results = predictor.generate_detailed_report(all_results)
    
    # SonuÃ§larÄ± gÃ¶rselleÅŸtir
    print("\nGrafik oluÅŸturuluyor...")
    predictor.visualize_results(avg_results)
    
    print("\nâœ… Analiz tamamlandÄ±! TÃ¼m Ã§Ä±ktÄ±lar 'outputs' klasÃ¶rÃ¼nde organize edildi.")
    print("ğŸ“Š Grafikler: outputs/graphs/ klasÃ¶rÃ¼nde")
    print("ğŸ“„ Raporlar: outputs/reports/ klasÃ¶rÃ¼nde")
    print("ğŸ¤– Modeller: outputs/models/ klasÃ¶rÃ¼nde")

if __name__ == "__main__":
    main()